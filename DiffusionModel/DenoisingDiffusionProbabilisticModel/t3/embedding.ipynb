{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# WORD EMBEDDINGS: ENCODING LEXICAL SEMANTICS\n",
    "## Word Embeddings in Pytorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Author: Robert Guthrie\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\"\"\"\n",
    "在神经网络中，参数默认是进行随机初始化的。如果不设置的话每次训练时的初始化都是随机的，导致结果不确定。如果设置初始化，则每次初始化都是固定的。\n",
    "\n",
    "如果使用多个GPU，应该使用torch.cuda.manual_seed_all()为所有的GPU设置种子。\n",
    "\"\"\"\n",
    "\n",
    "# 设置CPU的的随机数固定，使得紧跟着的rand()函数生成的值是固定的随机\n",
    "torch.manual_seed(1)\n",
    "torch.rand(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.7576, 0.2793, 0.4031, 0.7347, 0.0293])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.rand(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.3138, 0.1980, 0.4162, 0.2843, 0.3398])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7fc5784c5270>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sets the seed for generating random numbers. Returns a `torch.Generator` object.\n",
    "torch.manual_seed(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([0]), torch.Tensor, torch.Size([1]))"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "\n",
    "# 2 words in vocab, 5 dimensional embeddings\n",
    "embeds = nn.Embedding(num_embeddings=2, embedding_dim=5)\n",
    "\n",
    "# 获取单词‘hello’的索引（int 0）并将其转为tensor类型\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "\n",
    "lookup_tensor,type(lookup_tensor),lookup_tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.8923, -0.0583, -0.1955, -0.9656,  0.4224]],\n        grad_fn=<EmbeddingBackward0>),\n torch.Size([1, 5]))"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_embed = embeds(lookup_tensor)\n",
    "hello_embed,hello_embed.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.8923, -0.0583, -0.1955, -0.9656,  0.4224]],\n        grad_fn=<EmbeddingBackward0>),\n torch.Size([1, 5]))"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello_embed.view((1,-1))\n",
    "hello_embed,hello_embed.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 3.5870, -1.8313,  1.5987, -1.2770,  0.3255],\n         [-0.4791,  1.3790,  2.5286,  0.4107, -0.9880]],\n        grad_fn=<EmbeddingBackward0>),\n torch.Size([2, 5]))"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_tensor1 = torch.tensor([0,1], dtype=torch.long)\n",
    "all_embed = embeds(lookup_tensor1)\n",
    "all_embed,all_embed.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## An Example: N-Gram Language Modeling\n",
    "Recall that in an n-gram language model, given a sequence of words $w$, we want to compute $P(w_{i}|w_{i-1},w_{i-2},...,w_{i-n+1})$ Where $w_{i}$ is the $i$th word of the sequence."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this example, we will compute the loss function on some training examples and update the parameters with backpropagation.\n",
    "\"\"\"\n",
    "\n",
    "# 上下文的大小为2，即目标词的标签是其左右的两个词\n",
    "CONTEXT_SIZE = 2\n",
    "\n",
    "# 词嵌入的维数是10\n",
    "EMBEDDING_DIM = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "(['When',\n  'forty',\n  'winters',\n  'shall',\n  'besiege',\n  'thy',\n  'brow,',\n  'And',\n  'dig',\n  'deep',\n  'trenches',\n  'in',\n  'thy',\n  \"beauty's\",\n  'field,',\n  'Thy',\n  \"youth's\",\n  'proud',\n  'livery',\n  'so',\n  'gazed',\n  'on',\n  'now,',\n  'Will',\n  'be',\n  'a',\n  \"totter'd\",\n  'weed',\n  'of',\n  'small',\n  'worth',\n  'held:',\n  'Then',\n  'being',\n  'asked,',\n  'where',\n  'all',\n  'thy',\n  'beauty',\n  'lies,',\n  'Where',\n  'all',\n  'the',\n  'treasure',\n  'of',\n  'thy',\n  'lusty',\n  'days;',\n  'To',\n  'say,',\n  'within',\n  'thine',\n  'own',\n  'deep',\n  'sunken',\n  'eyes,',\n  'Were',\n  'an',\n  'all-eating',\n  'shame,',\n  'and',\n  'thriftless',\n  'praise.',\n  'How',\n  'much',\n  'more',\n  'praise',\n  \"deserv'd\",\n  'thy',\n  \"beauty's\",\n  'use,',\n  'If',\n  'thou',\n  'couldst',\n  'answer',\n  \"'This\",\n  'fair',\n  'child',\n  'of',\n  'mine',\n  'Shall',\n  'sum',\n  'my',\n  'count,',\n  'and',\n  'make',\n  'my',\n  'old',\n  \"excuse,'\",\n  'Proving',\n  'his',\n  'beauty',\n  'by',\n  'succession',\n  'thine!',\n  'This',\n  'were',\n  'to',\n  'be',\n  'new',\n  'made',\n  'when',\n  'thou',\n  'art',\n  'old,',\n  'And',\n  'see',\n  'thy',\n  'blood',\n  'warm',\n  'when',\n  'thou',\n  \"feel'st\",\n  'it',\n  'cold.'],\n 115)"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence,len(test_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "[(['forty', 'When'], 'winters'),\n (['winters', 'forty'], 'shall'),\n (['shall', 'winters'], 'besiege')]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    " we should tokenize the input, but we will ignore that for now build a list of tuples.\n",
    "\n",
    "Each tuple is ([ word_i-CONTEXT_SIZE, ..., word_i-1 ], target word)\n",
    "\n",
    "按照预设置的上下文大小构建元组（创建训练数据集）\n",
    "\"\"\"\n",
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
    "]\n",
    "\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "ngrams[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "97"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "构建每个单词的索引序列\n",
    "\"\"\"\n",
    "\n",
    "# 使用set()函数，返回一个无序不重复元素集\n",
    "vocab = set(test_sentence)\n",
    "# 单词数量为97\n",
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "{'thine!': 0,\n 'How': 1,\n 'when': 2,\n 'warm': 3,\n 'worth': 4,\n 'to': 5,\n 'shall': 6,\n \"youth's\": 7,\n 'use,': 8,\n 'dig': 9,\n 'own': 10,\n 'old': 11,\n 'Will': 12,\n 'lusty': 13,\n 'Thy': 14,\n 'Then': 15,\n 'more': 16,\n 'lies,': 17,\n 'on': 18,\n 'by': 19,\n 'field,': 20,\n 'Were': 21,\n 'thou': 22,\n 'This': 23,\n 'cold.': 24,\n 'deep': 25,\n 'besiege': 26,\n 'proud': 27,\n \"deserv'd\": 28,\n 'blood': 29,\n 'sum': 30,\n 'brow,': 31,\n 'so': 32,\n 'thy': 33,\n 'now,': 34,\n 'praise.': 35,\n 'art': 36,\n 'succession': 37,\n \"beauty's\": 38,\n 'trenches': 39,\n 'were': 40,\n 'livery': 41,\n 'where': 42,\n 'eyes,': 43,\n 'count,': 44,\n 'To': 45,\n 'within': 46,\n 'thine': 47,\n 'old,': 48,\n 'made': 49,\n 'praise': 50,\n 'all': 51,\n 'much': 52,\n 'of': 53,\n 'days;': 54,\n 'in': 55,\n 'sunken': 56,\n 'Shall': 57,\n 'If': 58,\n 'winters': 59,\n 'a': 60,\n \"excuse,'\": 61,\n 'the': 62,\n 'his': 63,\n 'say,': 64,\n 'held:': 65,\n 'an': 66,\n 'small': 67,\n 'weed': 68,\n 'my': 69,\n \"'This\": 70,\n 'answer': 71,\n 'fair': 72,\n 'And': 73,\n 'thriftless': 74,\n 'it': 75,\n 'gazed': 76,\n 'treasure': 77,\n \"feel'st\": 78,\n 'Proving': 79,\n 'new': 80,\n 'see': 81,\n 'shame,': 82,\n 'When': 83,\n 'make': 84,\n 'forty': 85,\n 'asked,': 86,\n 'couldst': 87,\n 'Where': 88,\n \"totter'd\": 89,\n 'child': 90,\n 'mine': 91,\n 'be': 92,\n 'beauty': 93,\n 'being': 94,\n 'and': 95,\n 'all-eating': 96}"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_ix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "构建模型\n",
    "- 非常简单的模型，只是用来展示embedding层的使用方法\n",
    "- 用的是很简单的线性层\n",
    "\"\"\"\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "\n",
    "        # 将vocab_size个单词嵌入维数为embedding_dim的空间，嵌入后的词向量表示为torch.Size([1, embedding_dim]))\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "\n",
    "        # 这里每次训练的词汇数（上下文数量）为context_size，故输入tensor形状为context_size * embedding_dim\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "\n",
    "        # 输出的结果大小为97，即单词的个数\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        # inputs.shape=torch.size([2])（context_size=2）\n",
    "        # self.embeddings(inputs).shape=torch.size([2,10])\n",
    "        # view相当于numpy里的resize\n",
    "        # view((1,-1))表示resize为1行的矩阵，-1表示列数自适应\n",
    "        # embeds.shape=torch.size([1,20])\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "\n",
    "\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "\n",
    "        out = self.linear2(out)\n",
    "\n",
    "        # 在softmax的结果上再做多一次log运算\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return log_probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "NGramLanguageModeler(\n  (embeddings): Embedding(97, 10)\n  (linear1): Linear(in_features=20, out_features=128, bias=True)\n  (linear2): Linear(in_features=128, out_features=97, bias=True)\n)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "定义训练所需组件\n",
    "- 模型\n",
    "- 损失函数\n",
    "- 优化器\n",
    "\"\"\"\n",
    "\n",
    "# 存储loss的列表\n",
    "losses = []\n",
    "\n",
    "# The negative log likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# 训练模型\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "\n",
    "# 优化器\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([85, 83]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([59, 85]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 6, 59]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([26,  6]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 26]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([31, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 31]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 9, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25,  9]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([39, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([55, 39]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 55]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([20, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([14, 20]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 7, 14]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([27,  7]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([41, 27]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([32, 41]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([76, 32]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([18, 76]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([34, 18]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([12, 34]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92, 12]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([60, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([89, 60]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([68, 89]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 68]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([67, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 4, 67]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([65,  4]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([15, 65]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([94, 15]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([86, 94]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([42, 86]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 42]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([17, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([88, 17]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([51, 88]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([62, 51]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([77, 62]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 77]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([13, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([54, 13]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([45, 54]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([64, 45]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([46, 64]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([47, 46]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([10, 47]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([25, 10]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([56, 25]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([43, 56]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([21, 43]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([66, 21]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([96, 66]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([82, 96]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 82]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([74, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([35, 74]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 1, 35]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([52,  1]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([16, 52]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([50, 16]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([28, 50]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 28]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([38, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 8, 38]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([58,  8]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22, 58]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([87, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([71, 87]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([70, 71]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([72, 70]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([90, 72]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([53, 90]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([91, 53]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([57, 91]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([30, 57]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 30]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([44, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([95, 44]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([84, 95]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([69, 84]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([11, 69]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([61, 11]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([79, 61]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([63, 79]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([93, 63]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([19, 93]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([37, 19]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 0, 37]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([23,  0]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([40, 23]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 5, 40]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([92,  5]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([80, 92]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([49, 80]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 2, 49]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([36, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([48, 36]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([73, 48]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([81, 73]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([33, 81]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([29, 33]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([ 3, 29]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([2, 3]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([22,  2]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([78, 22]), context_idxs.shape: torch.Size([2])\n",
      "context_idxs: tensor([75, 78]), context_idxs.shape: torch.Size([2])\n",
      "[518.595935344696, 516.3875434398651, 514.1909532546997, 512.0049066543579, 509.82784366607666, 507.6606137752533, 505.50306725502014, 503.3550064563751, 501.2137665748596, 499.07816457748413]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "\n",
    "    # 遍历训练集\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words into integer indices and wrap them in tensors)\n",
    "        # 获取context的词汇在word_to_ix的索引，并将其转为tensor类型\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        print(f'context_idxs: {context_idxs}, context_idxs.shape: {context_idxs.shape}')\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a new instance, you need to zero out the gradients from the old instance\n",
    "        # 梯度清零\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next words\n",
    "        log_probs = model(context_idxs)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target word wrapped in a tensor)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "\n",
    "# The loss decreased every iteration over the training data!\n",
    "print(losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0484, -0.0432,  1.2019, -0.0697,  1.0654, -0.8067, -0.1626, -0.7073,\n",
      "         0.2308, -1.5493], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# To get the embedding of a particular word, e.g. \"beauty\"\n",
    "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exercise: Computing Word Embeddings: Continuous Bag-of-Words(CBOW)\n",
    "CBOW是continuous bag of words的缩写，中文译为“连续词袋模型”。它是一种用于生成词向量的神经网络模型，由Tomas Mikolov等人于2013年提出 。词向量是一种将单词表示为固定长度的实数向量的方法，可以捕捉单词之间的语义和语法关系。\n",
    "\n",
    "CBOW的基本思想是，给定一个单词的上下文（即窗口内的其他单词），预测该单词本身。例如，对于句子“The cat climbed up the tree”，如果窗口大小为5，那么当中心单词为“climbed”时，上下文单词为“The”、“cat”、“up”和“the”。CBOW模型要求根据这四个上下文单词，计算出“climbed”的概率分布。\n",
    "\n",
    "![](../../img/1_1.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "['We',\n 'are',\n 'about',\n 'to',\n 'study',\n 'the',\n 'idea',\n 'of',\n 'a',\n 'computational',\n 'process.',\n 'Computational',\n 'processes',\n 'are',\n 'abstract',\n 'beings',\n 'that',\n 'inhabit',\n 'computers.',\n 'As',\n 'they',\n 'evolve,',\n 'processes',\n 'manipulate',\n 'other',\n 'abstract',\n 'things',\n 'called',\n 'data.',\n 'The',\n 'evolution',\n 'of',\n 'a',\n 'process',\n 'is',\n 'directed',\n 'by',\n 'a',\n 'pattern',\n 'of',\n 'rules',\n 'called',\n 'a',\n 'program.',\n 'People',\n 'create',\n 'programs',\n 'to',\n 'direct',\n 'processes.',\n 'In',\n 'effect,',\n 'we',\n 'conjure',\n 'the',\n 'spirits',\n 'of',\n 'the',\n 'computer',\n 'with',\n 'our',\n 'spells.']"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()\n",
    "\n",
    "# 按照空格划分单词并保存在列表中\n",
    "raw_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "data": {
      "text/plain": "{'As',\n 'Computational',\n 'In',\n 'People',\n 'The',\n 'We',\n 'a',\n 'about',\n 'abstract',\n 'are',\n 'beings',\n 'by',\n 'called',\n 'computational',\n 'computer',\n 'computers.',\n 'conjure',\n 'create',\n 'data.',\n 'direct',\n 'directed',\n 'effect,',\n 'evolution',\n 'evolve,',\n 'idea',\n 'inhabit',\n 'is',\n 'manipulate',\n 'of',\n 'other',\n 'our',\n 'pattern',\n 'process',\n 'process.',\n 'processes',\n 'processes.',\n 'program.',\n 'programs',\n 'rules',\n 'spells.',\n 'spirits',\n 'study',\n 'that',\n 'the',\n 'they',\n 'things',\n 'to',\n 'we',\n 'with'}"
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By deriving a set from `raw_text`, we deduplicate the array\n",
    "# 返回一个无序且不含重复元素的集合\n",
    "vocab = set(raw_text)\n",
    "vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "{'is': 0,\n 'things': 1,\n 'are': 2,\n 'conjure': 3,\n 'pattern': 4,\n 'evolve,': 5,\n 'The': 6,\n 'idea': 7,\n 'of': 8,\n 'about': 9,\n 'Computational': 10,\n 'process.': 11,\n 'processes': 12,\n 'we': 13,\n 'to': 14,\n 'computer': 15,\n 'that': 16,\n 'inhabit': 17,\n 'with': 18,\n 'our': 19,\n 'manipulate': 20,\n 'process': 21,\n 'People': 22,\n 'spirits': 23,\n 'spells.': 24,\n 'study': 25,\n 'create': 26,\n 'As': 27,\n 'directed': 28,\n 'computational': 29,\n 'called': 30,\n 'abstract': 31,\n 'by': 32,\n 'a': 33,\n 'rules': 34,\n 'the': 35,\n 'processes.': 36,\n 'they': 37,\n 'effect,': 38,\n 'other': 39,\n 'We': 40,\n 'programs': 41,\n 'computers.': 42,\n 'data.': 43,\n 'In': 44,\n 'beings': 45,\n 'direct': 46,\n 'program.': 47,\n 'evolution': 48}"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为每个单词生成索引\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "word_to_ix"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['are', 'We', 'to', 'study'], 'about'), (['about', 'are', 'study', 'the'], 'to'), (['to', 'about', 'the', 'idea'], 'study'), (['study', 'to', 'idea', 'of'], 'the'), (['the', 'study', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "生成训练样本\n",
    "- CONTEXT_SIZE = 2  # 2 words to the left, 2 to the right\n",
    "\"\"\"\n",
    "data = []\n",
    "for i in range(CONTEXT_SIZE, len(raw_text) - CONTEXT_SIZE):\n",
    "    context = (\n",
    "        [raw_text[i - j - 1] for j in range(CONTEXT_SIZE)]\n",
    "        + [raw_text[i + j + 1] for j in range(CONTEXT_SIZE)]\n",
    "    )\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "\n",
    "# 显示前5个训练样本\n",
    "data[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create your model and train. Here are some functions to help you make the data ready for use by your module.\n",
    "\"\"\"\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "make_context_vector(data[0][0], word_to_ix)  # example"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}