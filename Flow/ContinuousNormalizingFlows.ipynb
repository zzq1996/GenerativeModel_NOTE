{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Continuous Normalizing Flow\n",
    "## 1.Neural ODE\n",
    "## 2.Continuous Normalizing Flow"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6a493de071ceb84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural ODE\n",
    " \n",
    "\n",
    "---\n",
    "\n",
    "# **1.1. 传统神经网络的计算方式**\n",
    "在普通的神经网络（如 ResNet）中，我们的计算方式是**离散的**：\n",
    "$\\[\n",
    "h_{t+1} = h_t + f(h_t, \\theta)\n",
    "\\]$\n",
    "这里：\n",
    "- $\\( h_t \\)$ 表示**第 \\( t \\) 层的隐藏状态（hidden state）**，即神经网络的输出。\n",
    "- $\\( f(h_t, \\theta) \\)$ 是一个神经网络，表示数据的变化。\n",
    "- 这个公式表示：**每一层的计算都是一个离散跳跃**，从 $\\( h_t \\)$ 跳到 $\\( h_{t+1} \\)$。\n",
    "\n",
    "但这样做的缺点是：\n",
    "- 层数（depth）是固定的，不能动态调整。\n",
    "- 计算是离散的，不能描述连续的变化。\n",
    "\n",
    "---\n",
    "\n",
    "# **1.2. Neural ODE 的数学表达**\n",
    "Neural ODE 的核心思想是：**把离散的计算过程变成连续的变化**，用**常微分方程（ODE）**描述神经网络的演化过程：\n",
    "$\\[\n",
    "\\frac{dh(t)}{dt} = f(h(t), t, \\theta)\n",
    "\\]$\n",
    "这是一个**微分方程**，表示 $\\( h(t) \\)$ 在连续时间 $\\( t \\)$上的变化规律。\n",
    "\n",
    "## **1.2.1 这是什么意思？**\n",
    "- **$\\( h(t) \\)$ 是一个连续时间的隐藏状态**，不像传统网络那样按照层的编号 $\\( h_1, h_2, \\dots \\)$ 来索引。\n",
    "- **$\\( f(h, t, \\theta) \\)$ 是一个神经网络**，它告诉我们**隐藏状态如何随时间变化**。\n",
    "- **$\\( \\frac{dh}{dt} \\)$ 代表变化率**，可以理解为 ResNet 的离散差分公式：\n",
    "  $\\[\n",
    "  h_{t+1} - h_t = f(h_t, \\theta)\n",
    "  \\]$\n",
    "  变成连续版本：\n",
    "  $\\[\n",
    "  \\frac{dh}{dt} = f(h, t, \\theta)\n",
    "  \\]$\n",
    "  这表示 $\\( h(t) \\)$ 在时间上的变化不再是固定的离散步长，而是一个**连续的过程**。\n",
    "\n",
    "---\n",
    "\n",
    "## **1.3. 计算隐藏状态 $\\( h(T) \\)$**\n",
    "在传统神经网络中，我们通过多个层的计算来得到最终的输出：\n",
    "$\\[\n",
    "h_T = h_0 + \\sum_{t=0}^{T-1} f(h_t, \\theta)\n",
    "\\]$\n",
    "在 Neural ODE 中，我们用微积分的思想，把这个求和变成积分：\n",
    "$\\[\n",
    "h(T) = h(0) + \\int_{0}^{T} f(h(t), t, \\theta) dt\n",
    "\\]$\n",
    "这就是**微分方程的求解**！\n",
    "\n",
    "### **1.3.1 这是什么意思？**\n",
    "- 我们知道 **$\\( \\frac{dh}{dt} = f(h, t, \\theta) \\)$**，表示 $\\( h(t) \\)$ 的变化速度。\n",
    "- 为了计算 $\\( h(T) \\)$，我们需要在时间区间 $\\( [0, T] \\)$ 内把所有的变化累加起来，这就是积分的作用。\n",
    "- 这意味着 Neural ODE 通过**求解微分方程（ODE Solver）** 来得到最终的隐藏状态 $\\( h(T) \\)$。\n",
    "\n",
    "### **1.3.2 用 ODE 求解器计算 $\\( h(T) \\)$**\n",
    "由于这个方程没有显式解，我们通常用 **数值方法（Numerical Methods）** 来求解，比如：\n",
    "- **Euler 方法（欧拉法）**：最简单的方式，把时间离散化：\n",
    "  $\\[\n",
    "  h(t + \\Delta t) = h(t) + \\Delta t \\cdot f(h, t, \\theta)\n",
    "  \\]$\n",
    "- **Runge-Kutta 方法（常用的 ODE 求解器）**，更精确。\n",
    "- **Adaptive ODE Solver（自适应 ODE 求解器）**，可以根据误差动态调整步长，提高效率。\n",
    "\n",
    "在代码实现时，我们通常调用 PyTorch 的 `torchdiffeq.odeint` 来求解：\n",
    "```python\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "h_T = odeint(f, h_0, t, theta)  # 计算从 h(0) 到 h(T) 的演化\n",
    "```\n",
    "这里 `odeint` 会自动调用 ODE 求解器，计算 $\\( h(T) \\)$。\n",
    "\n",
    "更详细的表述：\n",
    "\n",
    "我们可以用一个简单的比喻和步骤来解释这个过程，不需要太多复杂的数学知识。假设你在观察一辆汽车的运动，而这辆汽车的“运动规则”由一个神经网络给出，这个神经网络就是函数 \\( f(z(t), t, \\theta) \\)。\n",
    "\n",
    "### 比喻：汽车行驶过程\n",
    "\n",
    "1. **汽车的位置和速度**  \n",
    "   - **位置 \\( z(t) \\)**：表示汽车在时间 \\( t \\) 的位置。  \n",
    "   - **速度 \\( \\frac{dz(t)}{dt} \\)**：表示汽车在时间 \\( t \\) 的行驶速度。\n",
    "\n",
    "2. **神经网络 \\( f(z(t), t, \\theta) \\)**  \n",
    "   - 这个函数告诉我们，在给定位置 \\( z(t) \\) 和时间 \\( t \\) 下，汽车的行驶速度是多少。  \n",
    "   - 参数 \\(\\theta\\) 就像是“驾驶风格”或“路况”参数，决定了具体的行驶方式。\n",
    "\n",
    "3. **问题描述**  \n",
    "   - **已知**：汽车在起点时的位置 \\( z(t_0) \\)（例如家门口）。\n",
    "   - **目标**：知道汽车从 \\( t_0 \\) 行驶到 \\( t_1 \\) 后，到达了什么位置 \\( z(t_1) \\)。\n",
    "\n",
    "在数学上，我们描述这一过程的微分方程为：\n",
    "\\[\n",
    "\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "\\]\n",
    "这意味着：汽车在任何时刻的“即时速度”，都是由函数 \\( f \\) 决定的。\n",
    "\n",
    "---\n",
    "\n",
    "### 数值积分器（ODE Solver）的工作原理\n",
    "\n",
    "由于我们一般无法直接写出 \\( z(t_1) \\) 的精确表达式，所以需要借助数值积分器来“模拟”汽车的行驶过程。我们如何来做呢？下面是一种简单的思路：\n",
    "\n",
    "1. **将时间分成许多小步**  \n",
    "   把从 \\( t_0 \\) 到 \\( t_1 \\) 这一大段时间，分成很多很短的小时间间隔，比如 \\( h \\) 秒。例如：\n",
    "   \\[\n",
    "   t_0,\\, t_0 + h,\\, t_0 + 2h,\\, \\ldots,\\, t_1\n",
    "   \\]\n",
    "\n",
    "2. **从起点开始，逐步更新位置**  \n",
    "   - **初始时刻**：汽车的位置为 \\( z(t_0) \\)。\n",
    "   - **第一步**：在时间 \\( t_0 \\)，计算速度 \\( f(z(t_0), t_0, \\theta) \\)。因为 \\( h \\) 很小，我们可以近似认为在这 \\( h \\) 秒内汽车的速度不变。所以在 \\( t_0 + h \\) 时，汽车大约走过的距离是 \\( h \\times f(z(t_0), t_0, \\theta) \\)。于是，我们更新位置：\n",
    "     \\[\n",
    "     z(t_0+h) \\approx z(t_0) + h \\times f(z(t_0), t_0, \\theta)\n",
    "     \\]\n",
    "   - **后续步骤**：然后在 \\( t_0+h \\) 时，再次用同样的方法计算速度 \\( f(z(t_0+h), t_0+h, \\theta) \\)，再更新位置：\n",
    "     \\[\n",
    "     z(t_0+2h) \\approx z(t_0+h) + h \\times f(z(t_0+h), t_0+h, \\theta)\n",
    "     \\]\n",
    "     重复这个过程，直到时间达到 \\( t_1 \\)。\n",
    "\n",
    "3. **更高级的数值方法**  \n",
    "   上面描述的是最简单的**Euler方法**。实际上，我们通常会用更精确的方法，比如**Runge-Kutta方法**。这种方法在每个时间步中，会在多个点上估计 \\( f \\) 的值，然后综合这些信息来更准确地更新 \\( z(t) \\)。简单来说，它就是在每一步中“多次询问”神经网络 \\( f \\) 的意见，从而更好地预测汽车下一个位置。\n",
    "\n",
    "---\n",
    "\n",
    "### 总结\n",
    "\n",
    "- **目标**：我们希望知道汽车从起点 $\\( z(t_0) \\)$ 到终点 $\\( z(t_1) \\)$ 的位置。\n",
    "- **方法**：用数值积分器来模拟这一过程，即：\n",
    "  1. 将时间区间 $\\( [t_0, t_1] \\)$ 划分成很多小步。\n",
    "  2. 每一步都用神经网络 $\\( f(z(t), t, \\theta) \\)$ 给出的速度来更新汽车的位置。\n",
    "  3. 逐步累加每一步的小变化，最终得到 $\\( z(t_1) \\)$。\n",
    "\n",
    "这样，通过不断地“小步”前进，我们就能“积分”（累加）这些速度信息，得到从 $\\( t_0 \\)$ 到 $\\( t_1 \\)$ 的整体位移。这就是如何借助数值积分器（ODE Solver）来求解 Neaural ODE 的核心思想。\n",
    "\n",
    "如果还有其他疑问或者需要进一步解释某一部分，请随时告诉我！\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **1.4. 直观理解 Neural ODE**\n",
    "我们可以把 Neural ODE 形象地理解为**粒子在力场中的运动**：\n",
    "- 传统神经网络是一条**固定的阶梯**，每一层都是一个离散的跳跃。\n",
    "- Neural ODE 是一个**平滑的轨迹**，数据点像粒子一样在**连续的向量场（vector field）**中流动。\n",
    "\n",
    "一个典型的示例是 Normalizing Flows（如 FFJORD），它用 Neural ODE 让数据点在一个流体场中平滑变换，如下图：\n",
    "\n",
    "📈 **数据流动的可视化**\n",
    "（左：普通流模型，右：Neural ODE 生成的数据流）\n",
    "\n",
    "```\n",
    "传统流模型：\n",
    "o-----> o -----> o -----> o\n",
    "\n",
    "Neural ODE：\n",
    "o---o---o---o---o  （连续变化）\n",
    "```\n",
    "\n",
    "这种连续变化可以让模型更自然地学习数据的分布，提高生成能力。\n",
    "\n",
    "---\n",
    "\n",
    "# **1.5. Neural ODE vs. 传统神经网络**\n",
    "| 特性 | 传统神经网络                                         | Neural ODE                                                         |\n",
    "|------|------------------------------------------------|--------------------------------------------------------------------|\n",
    "| 计算方式 | 通过离散层计算 $\\( h_{t+1} = h_t + f(h_t, \\theta) \\)$ | 通过 ODE 求解器计算 $\\( h(T) = h(0) + \\int_{0}^{T} f(h, t, \\theta) dt \\)$ |\n",
    "| 结构 | 固定层数                                           | 动态计算，层数不固定                                                         |\n",
    "| 内存占用 | 需要存储所有中间层                                      | 只存储初始状态，**内存占用低**                                                  |\n",
    "| 适用任务 | 传统分类、回归                                        | **时间序列建模、生成模型**                                                    |\n",
    "\n",
    "---\n",
    "\n",
    "# **1.6. 总结**\n",
    "1. **Neural ODE 通过连续时间微分方程建模神经网络的变化**：\n",
    "   $\\[\n",
    "   \\frac{dh}{dt} = f(h, t, \\theta)\n",
    "   \\]$\n",
    "   **这个公式的作用**：\n",
    "   - 让隐藏状态 $\\( h(t) \\)$ 变成一个连续函数，而不是固定的层。\n",
    "   - 计算 $\\( h(T) \\)$ 时，不是用固定层数的计算，而是求解一个 ODE。\n",
    "  \n",
    "2. **计算方式**：用 ODE 求解器计算隐藏状态的演化：\n",
    "   $\\[\n",
    "   h(T) = h(0) + \\int_{0}^{T} f(h, t, \\theta) dt\n",
    "   \\]$\n",
    "\n",
    "3. **Neural ODE 的优势**：\n",
    "   - **计算更加灵活**，层数可以动态调整，而不是固定的网络结构。\n",
    "   - **内存占用更低**，不需要存储所有中间层。\n",
    "   - **适用于时间序列建模、流体动力学、生成模型（如 FFJORD）**。\n",
    "\n",
    "如果你还不明白，可以想象：\n",
    "- 传统神经网络 = **楼梯**（每一层是一个固定的台阶）。\n",
    "- Neural ODE = **滑梯**（隐藏状态连续变化，没有固定的层数）。\n",
    "\n",
    "这样，Neural ODE 就像一个**平滑的流动过程**，而不是跳跃式的计算！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69c10fc68a6176de"
  },
  {
   "cell_type": "markdown",
   "source": [
    "好的，下面我举一个具体的例子，展示如何将三层残差网络（ResNet）转化为基于常微分方程（ODE）的网络。\n",
    "\n",
    "### 1. **三层残差网络（ResNet）**\n",
    "我们从一个简单的三层残差网络开始，假设每一层的输入为 \\( z_k \\)，每一层都包含一个残差连接。具体来说，三层 ResNet 的结构可以描述为：\n",
    "\n",
    "#### 第 1 层：\n",
    "$\\[\n",
    "z_1 = z_0 + f_1(z_0, \\theta_1)\n",
    "\\]$\n",
    "这里，$\\( f_1(z_0, \\theta_1) \\)$ 是第 $1$ 层的操作，可能是一个卷积层或者全连接层，$\\(\\theta_1\\)$ 是该层的参数。\n",
    "\n",
    "#### 第 2 层：\n",
    "$\\[\n",
    "z_2 = z_1 + f_2(z_1, \\theta_2)\n",
    "\\]$\n",
    "同理，$\\( f_2(z_1, \\theta_2) \\)$ 是第 $2$ 层的操作，$\\(\\theta_2\\)$ 是该层的参数。\n",
    "\n",
    "#### 第 3 层：\n",
    "$\\[\n",
    "z_3 = z_2 + f_3(z_2, \\theta_3)\n",
    "\\]$\n",
    "$\\( f_3(z_2, \\theta_3) \\)$ 是第 3 层的操作，$\\(\\theta_3\\)$ 是该层的参数。\n",
    "\n",
    "这样，三层残差网络的输出是：\n",
    "$\\[\n",
    "z_3 = z_0 + f_1(z_0, \\theta_1) + f_2(z_1, \\theta_2) + f_3(z_2, \\theta_3)\n",
    "\\]$\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **将三层残差网络转为 ODE**\n",
    "\n",
    "为了将三层残差网络转化为 ODE，我们需要将离散的层次结构转化为一个连续的时间动态系统。基本思想是用一个微分方程来替代每一层的离散更新。具体来说，我们希望定义一个连续时间的状态演化过程，使得在 $\\( t_0 \\)$ 到 $\\( t_1 \\)$ 的时间间隔内，状态 $\\( z(t) \\)$ 会不断演化，并且能够表达出原始的残差连接。\n",
    "\n",
    "#### ODE 表述\n",
    "\n",
    "假设我们将每一层的更新规则（$\\( f_k(z_k, \\theta_k) \\)$）转化为一个微分方程。我们可以为每一层的更新定义一个微分方程：\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "\\]$\n",
    "在这个方程中，$\\( f(z(t), t, \\theta) \\)$ 是一个神经网络，用来表示状态 $\\( z(t) \\)$ 在时间 $\\( t \\)$ 上的变化。\n",
    "\n",
    "### 3. **构建连续的 ODE**\n",
    "\n",
    "为了得到一个连续的网络，我们将每一层的离散残差更新转化为一个在连续时间域中的状态更新。\n",
    "\n",
    "我们首先为 $\\( t \\)$ 设定一个时间范围，比如从 $\\( t_0 = 0 \\)$ 到 $\\( t_1 = 1 \\)$（这里的时间单位只是为了表示状态的变化，而非实际时间）。然后我们定义一个微分方程，表示状态 $\\( z(t) \\)$ 在时间上的演化。\n",
    "\n",
    "- 在残差网络中，我们有 $\\( z_1 = z_0 + f_1(z_0, \\theta_1) \\)$，因此我们可以将其转化为：\n",
    "  $\\[\n",
    "  \\frac{dz(t)}{dt} = f(z(t), t, \\theta_1)\n",
    "  \\]$\n",
    "- 对于接下来的层，我们可以使用类似的思路：\n",
    "  $\\[\n",
    "  \\frac{dz(t)}{dt} = f(z(t), t, \\theta_2)\n",
    "  \\]$\n",
    "  和\n",
    "  $\\[\n",
    "  \\frac{dz(t)}{dt} = f(z(t), t, \\theta_3)\n",
    "  \\]$\n",
    "\n",
    "将这些过程连贯地结合在一起，我们可以通过连续的微分方程来表示残差网络的演化。\n",
    "\n",
    "### 4. **数值求解 ODE**\n",
    "\n",
    "在实际应用中，我们无法直接解析求解这个微分方程，因此我们使用数值方法（例如 Runge-Kutta 方法）来进行求解。给定初始状态 $\\( z(t_0) = z_0 \\)$，我们通过数值积分器来计算从 $\\( t_0 \\)$ 到 $\\( t_1 \\)$ 的状态 $\\( z(t_1) \\)$。\n",
    "\n",
    "### 5. **如何实现**\n",
    "\n",
    "如果你要将这个 ODE 表达式用代码实现，可以采用如下伪代码：\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "# 假设 f(t, z, theta) 是一个神经网络表示\n",
    "def f(t, z, theta):\n",
    "    # 这是你定义的神经网络模型\n",
    "    return neural_network(z, theta)\n",
    "\n",
    "# 初始状态\n",
    "z0 = torch.zeros(batch_size, input_dim)  # 假设 z(t_0) = z_0\n",
    "\n",
    "# 时间范围\n",
    "t_span = torch.linspace(0., 1., steps=100)\n",
    "\n",
    "# 通过 ODE 求解器求解状态变化\n",
    "solution = odeint(f, z0, t_span, args=(theta,))\n",
    "```\n",
    "\n",
    "在这个代码中，我们通过 `odeint` 来求解 ODE，`f` 是一个神经网络，用来描述状态随时间的变化。`theta` 是神经网络的参数，`z0` 是初始状态。\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **总结**\n",
    "\n",
    "- **ResNet** 通过离散的层进行残差学习，每一层都独立更新状态并与前一层相加。\n",
    "- **ODE 网络** 则通过定义一个连续的微分方程来描述状态随时间的演化，这个方程本质上是将残差层的离散更新转化为连续动态系统。\n",
    "- 在 ODE 网络中，状态的演化不是通过固定的层次进行的，而是通过数值积分来模拟状态随时间的变化。最终，网络的输出是通过数值求解微分方程得到的。\n",
    "\n",
    "通过这种方式，ResNet 可以看作是一个离散时间的 ODE 网络，而 Neural ODE 则是一个连续时间的网络。希望这个例子能帮助你理解如何从残差网络转化到 ODE 网络！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "475b5cd79fd7cdf7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Ordinary Differential Equations做了什么？\n",
    "\n",
    "在 Neural ODE 中，梯度计算是一个重要的环节，尤其是在反向传播过程中。因为传统的神经网络是通过逐层的前向和反向传播来计算梯度，而 Neural ODE 是通过求解一个连续的常微分方程（ODE）来描述状态的演化，所以在反向传播过程中需要考虑如何计算损失对网络参数的梯度。直接对 ODE 求解过程反向传播（即计算损失关于 ODE 求解过程的梯度）可能会导致内存和计算开销非常大。因此，**Neural ODE 论文提出了伴随敏感性方法（Adjoint Sensitivity Method）**，它能有效地计算梯度，并且显著减少内存消耗。\n",
    "\n",
    "### 1. **背景：传统反向传播中的内存消耗问题**\n",
    "\n",
    "在传统的神经网络中，反向传播的过程可以通过链式法则逐层计算梯度。对于一个具有 $\\(L\\)$ 层的神经网络，反向传播需要存储每一层的激活值和梯度。因此，对于深层网络，内存消耗随着网络深度的增加而增加。\n",
    "\n",
    "对于 **Neural ODE**，反向传播不仅需要计算参数的梯度，还需要计算**ODE解的梯度**。这是因为在训练过程中，网络的状态是通过解微分方程得到的，所以在反向传播时，我们需要计算损失函数关于ODE解的梯度。\n",
    "\n",
    "- 在前向传播中，**ODE求解器**需要逐步计算状态 $\\(z(t)\\)$ 从 $\\(t_0\\)$ 到 $\\(t_1\\)$ 的演化，可能会产生大量的中间状态。\n",
    "- 在反向传播时，通常需要反向传播每一时刻的中间状态，来计算梯度。这就需要**存储每一个时间步的中间状态**，从而导致**巨大的内存消耗**。\n",
    "\n",
    "### 2. **伴随敏感性方法（Adjoint Sensitivity Method）**\n",
    "\n",
    "为了解决上述问题，Neural ODE 引入了 **伴随敏感性方法**，这是一种计算梯度的高效方法。通过这一方法，我们可以避免存储每个时间步的中间状态，从而显著减少内存消耗。\n",
    "\n",
    "#### 2.1 伴随状态的定义\n",
    "\n",
    "设损失函数 $\\(L\\)$ 依赖于最终状态 $\\(z(t_1)\\)$，我们需要计算损失关于参数 $\\(\\theta\\)$ 的梯度：\n",
    "$\\[\n",
    "\\frac{\\partial L}{\\partial \\theta}\n",
    "\\]$\n",
    "由于 $\\(z(t_1)\\)$ 是通过求解微分方程得到的，我们可以通过链式法则来计算梯度：\n",
    "$\\[\n",
    "\\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial z(t_1)} \\cdot \\frac{\\partial z(t_1)}{\\partial \\theta}\n",
    "\\]$\n",
    "但问题是，$\\( \\frac{\\partial z(t_1)}{\\partial \\theta} \\)$ 的计算可能涉及存储大量中间状态（因为求解ODE时需要知道每一个时间步的状态）。\n",
    "\n",
    "为了避免这种存储开销，**伴随敏感性方法**引入了**伴随状态**（adjoint state）。\n",
    "\n",
    "#### 2.2 伴随方程\n",
    "\n",
    "我们定义伴随状态 $\\(a(t)\\)$ 为：\n",
    "$\\[\n",
    "a(t) = \\frac{\\partial L}{\\partial z(t)}\n",
    "\\]$\n",
    "伴随状态的作用是描述损失函数 $\\(L\\)$ 对隐状态 $\\(z(t)\\)$ 的敏感性。\n",
    "\n",
    "通过链式法则，损失对参数 \\(\\theta\\) 的梯度可以写成：\n",
    "\\[\n",
    "\\frac{\\partial L}{\\partial \\theta} = \\int_{t_0}^{t_1} a(t)^\\top \\frac{\\partial f(z(t), t, \\theta)}{\\partial \\theta} \\, dt\n",
    "\\]\n",
    "这里，\\(f(z(t), t, \\theta)\\) 是用于描述ODE动态的神经网络，\\(\\frac{\\partial f}{\\partial \\theta}\\) 是网络参数的梯度。\n",
    "\n",
    "#### 2.3 伴随状态的演化方程\n",
    "\n",
    "伴随状态 \\(a(t)\\) 也需要满足一个微分方程，它的演化方向与时间是相反的。我们可以推导出伴随状态 \\(a(t)\\) 满足以下方程：\n",
    "\\[\n",
    "\\frac{da(t)}{dt} = - a(t)^\\top \\frac{\\partial f(z(t), t, \\theta)}{\\partial z(t)}\n",
    "\\]\n",
    "边界条件为：\n",
    "\\[\n",
    "a(t_1) = \\frac{\\partial L}{\\partial z(t_1)}\n",
    "\\]\n",
    "这个方程描述了伴随状态的演化，它与ODE的解是反向的。\n",
    "\n",
    "#### 2.4 计算梯度的步骤\n",
    "\n",
    "使用伴随敏感性方法，反向传播的过程如下：\n",
    "\n",
    "1. **初始化伴随状态**：在时间 \\(t_1\\) 处，计算伴随状态 \\(a(t_1)\\)，即：\n",
    "   \\[\n",
    "   a(t_1) = \\frac{\\partial L}{\\partial z(t_1)}\n",
    "   \\]\n",
    "   \n",
    "2. **反向传播伴随状态**：从 \\(t_1\\) 开始，沿着时间反向积分伴随方程：\n",
    "   \\[\n",
    "   \\frac{da(t)}{dt} = - a(t)^\\top \\frac{\\partial f(z(t), t, \\theta)}{\\partial z(t)}\n",
    "   \\]\n",
    "   计算伴随状态 \\(a(t)\\) 的演化，直到达到 \\(t_0\\)。\n",
    "\n",
    "3. **计算梯度**：最后，使用伴随状态 \\(a(t)\\) 来计算损失对参数 \\(\\theta\\) 的梯度：\n",
    "   \\[\n",
    "   \\frac{\\partial L}{\\partial \\theta} = \\int_{t_0}^{t_1} a(t)^\\top \\frac{\\partial f(z(t), t, \\theta)}{\\partial \\theta} \\, dt\n",
    "   \\]\n",
    "   这个梯度可以用于参数更新（例如通过梯度下降等优化算法）。\n",
    "\n",
    "### 3. **内存消耗与效率**\n",
    "\n",
    "- **内存优化**：通过伴随敏感性方法，我们无需存储每个时间步的中间状态。相反，我们只需要在反向传播时，计算伴随状态并沿时间反向积分。这样，内存消耗大大降低。\n",
    "- **计算效率**：尽管伴随敏感性方法需要进行反向积分计算，但与存储和反向传播每个时间步的中间状态相比，它显著减少了内存开销。此外，随着深度网络的增加，这种方法在效率上的优势更加明显。\n",
    "\n",
    "### 4. **伪代码实现**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torchdiffeq import odeint\n",
    "\n",
    "def f(t, z, theta):\n",
    "    # 这里的 f 是描述ODE动态的神经网络\n",
    "    return neural_network(z, theta)\n",
    "\n",
    "def adjoint_sensitivity_method(dL_dz_t1, z_traj, t_span, theta):\n",
    "    # 初始化伴随状态\n",
    "    a_t1 = dL_dz_t1\n",
    "    \n",
    "    # 定义伴随方程和参数梯度的联合 ODE\n",
    "    def augmented_dynamics(t, aug_state):\n",
    "        z, a, grad_theta = aug_state\n",
    "        f_val = f(z, t, theta)\n",
    "        df_dz = compute_jacobian_z(f, z, t, theta)\n",
    "        df_dtheta = compute_jacobian_theta(f, z, t, theta)\n",
    "        \n",
    "        da_dt = -torch.matmul(a, df_dz)  # 伴随方程\n",
    "        dz_dt = f_val\n",
    "        dgrad_theta_dt = -torch.matmul(a, df_dtheta)  # 参数梯度累加\n",
    "        \n",
    "        return (dz_dt, da_dt, dgrad_theta_dt)\n",
    "    \n",
    "    # 初始化增强状态\n",
    "    aug_state_t1 = (z_traj[-1], a_t1, torch.zeros_like(theta))\n",
    "    \n",
    "    # 反向积分：从 t1 到 t0\n",
    "    z_t0, a_t0, grad_theta = odeint(augmented_dynamics, aug_state_t1, t_span.flip(0))\n",
    "    \n",
    "    return grad_theta\n",
    "```\n",
    "\n",
    "### 5. **总结**\n",
    "\n",
    "- **伴随敏感性方法**通过反向求解一个与ODE解反向的伴随方程，来计算梯度。\n",
    "- 这种方法避免了存储每个时间步的中间状态，从而大大减少了内存消耗。\n",
    "- 反向传播过程中，我们首先初始化伴随状态，然后沿时间反向计算梯度，最后使用伴随状态计算参数的梯度。\n",
    "- 伴随敏感性方法使得 Neural ODE 在计算上更加高效，尤其适用于深层网络和长时间序列问题。\n",
    "\n",
    "这个方法非常适合处理深度连续网络的训练，并且能有效地减少内存消耗。如果有任何问题，或需要更详细的解释，欢迎继续提问！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed95b5c5cc39d695"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 如何理解网络的输出z(t1)?\n",
    "是的，**Neural ODE** 中的最终输出 \\( z(t_1) \\) **就是 ODE 的解**。\n",
    "\n",
    "### 1. **Neural ODE 中的 ODE 解**\n",
    "\n",
    "Neural ODE 的核心思想是使用一个常微分方程（ODE）来描述网络的状态随时间的变化。具体来说，给定初始状态 $\\( z(t_0) \\)$ 和微分方程：\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "\\]$\n",
    "其中 $\\( f(z(t), t, \\theta) \\)$ 是一个神经网络（通常是一个多层感知机），它描述了状态 $\\( z(t) \\)$ 随时间 $\\( t \\)$ 的演化，$\\(\\theta\\)$ 是网络的参数。\n",
    "\n",
    "在 **Neural ODE** 中，网络的输出 $\\( z(t_1) \\)$ 是通过解这个微分方程得到的。具体来说，给定初始状态 $\\( z(t_0) \\)$，我们通过数值求解方法（例如欧拉法、Runge-Kutta 方法等）对该 ODE 进行求解，得到终点 $\\( t_1 \\)$ 处的状态 $\\( z(t_1) \\)$。\n",
    "\n",
    "### 2. **如何理解 \\( z(t_1) \\) 是 ODE 的解？**\n",
    "\n",
    "在传统的神经网络中，网络的层级通过离散的层次结构进行，状态从输入到输出经过多个计算步骤。而在 **Neural ODE** 中，网络的状态通过微分方程进行描述，状态随时间的变化是连续的，而不是离散的。\n",
    "\n",
    "- **初始状态**：假设网络的初始状态 $\\( z(t_0) \\)$ 在 $\\( t_0 \\)$ 时刻给定。\n",
    "- **ODE 方程**：微分方程 $\\(\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\\)$ 描述了状态 $\\( z(t) \\)$ 如何随时间 $\\( t \\)$ 演化。这个方程的右边是神经网络 $\\( f \\)$，它基于当前状态和时间来预测状态的变化。\n",
    "- **数值求解**：通过数值积分方法（例如欧拉法、Runge-Kutta 等），我们可以计算从 $\\( t_0 \\)$ 到 $\\( t_1 \\)$ 的状态变化，得到 $\\( z(t_1) \\)$，即在终止时间 $\\( t_1 \\)$ 时刻的状态。\n",
    "\n",
    "这个计算过程实际上是对 **ODE 解的求解**，因此 $\\( z(t_1) \\)$ 就是由微分方程描述的系统在时间 $\\( t_1 \\)$ 的解。\n",
    "\n",
    "### 3. **Neural ODE 的输出**\n",
    "- 在 **Neural ODE** 中，最终的输出 $\\( z(t_1) \\)$ 是通过解这个微分方程 $\\( \\frac{dz(t)}{dt} = f(z(t), t, \\theta) \\)$ 得到的。\n",
    "- 换句话说，$\\( z(t_1) \\)$ 反映了网络从初始状态 $\\( z(t_0) \\)$ 到终止状态 $\\( z(t_1) \\)$ 的演化过程，它是神经网络在一个连续时间动态系统中的表现。\n",
    "\n",
    "### 4. **总结**\n",
    "在 **Neural ODE** 中，最终的输出 $\\( z(t_1) \\)$ 确实是 ODE 的解。通过数值求解微分方程，我们得到网络状态在时间 $\\( t_1 \\)$ 的值，而这个过程可以看作是对微分方程的解的计算。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "264c0e35c6170d63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 为什么不仅要计算损失关于网络参数的梯度，还需要计算损失关于 ODE解 z(t1）的梯度？\n",
    "\n",
    "这是一个很好的问题，关键在于理解链式法则（chain rule）在反向传播中的作用。简单来说，虽然我们的最终目标是更新网络参数 $\\(\\theta\\)$，但网络的输出 $\\(z(t_1)\\)$ 是先由参数 $\\(\\theta\\)$ 生成的，再用于计算损失 $\\(L\\)$。因此，我们必须知道损失 $\\(L\\)$ 对 $\\(z(t_1)\\)$ 的敏感性，也就是 $\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$，才能进一步计算 $\\(\\theta\\)$ 的梯度。\n",
    "\n",
    "让我们一步一步地来看：\n",
    "\n",
    "### 1. 输出是参数的函数\n",
    "\n",
    "在 Neural ODE 中，最终的输出 $\\(z(t_1)\\)$ 是通过积分一个依赖于参数 $\\(\\theta\\)$ 的微分方程得到的：\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "\\]$\n",
    "这意味着 $\\(z(t_1)\\)$ 实际上是参数 $\\(\\theta\\)$ 的一个函数，我们可以写作：\n",
    "$\\[\n",
    "z(t_1) = g(\\theta)\n",
    "\\]$\n",
    "因此，损失 $\\(L\\)$ 也变成了参数 $\\(\\theta\\)$ 的函数：\n",
    "$\\[\n",
    "L = L(z(t_1)) = L(g(\\theta))\n",
    "\\]$\n",
    "\n",
    "### 2. 链式法则的作用\n",
    "\n",
    "根据链式法则，参数 $\\(\\theta\\)$ 的梯度可以写为：\n",
    "$\\[\n",
    "\\frac{\\partial L}{\\partial \\theta} = \\frac{\\partial L}{\\partial z(t_1)} \\cdot \\frac{\\partial z(t_1)}{\\partial \\theta}\n",
    "\\]$\n",
    "这表示：\n",
    "- **第一部分**：$\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$ —— 损失函数对最终输出 $\\(z(t_1)\\)$ 的敏感性，也就是当 $\\(z(t_1)\\)$ 发生微小变化时，损失 $\\(L\\)$ 会如何变化。\n",
    "- **第二部分**：$\\(\\frac{\\partial z(t_1)}{\\partial \\theta}\\)$ —— 最终输出 \\(z(t_1)\\) 对网络参数 \\(\\theta\\) 的敏感性，也就是当参数 \\(\\theta\\) 改变时，\\(z(t_1)\\) 会如何变化。\n",
    "\n",
    "### 3. 为什么必须计算 $\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$\n",
    "\n",
    "如果我们仅仅计算“关于网络参数的梯度”，那实际上是计算整个链式法则的右边部分。然而，由于 \\(z(t_1)\\) 不是直接由 \\(\\theta\\) 线性生成的，而是经过了一个复杂的动态过程（ODE 求解），我们无法直接“跳过”中间的 \\(z(t_1)\\) 部分。必须明确知道损失对 \\(z(t_1)\\) 的变化率，也就是 \\(\\frac{\\partial L}{\\partial z(t_1)}\\)，才能通过链式法则进一步传播到参数 \\(\\theta\\) 上。\n",
    "\n",
    "用一个直观的比喻来理解：  \n",
    "- 想象你要知道“改变发动机部件（参数 \\(\\theta\\)）对汽车速度（\\(z(t_1)\\)）的影响”，再知道“汽车速度的改变对燃油消耗（损失 \\(L\\)）的影响”。  \n",
    "- 如果你只知道“改变发动机部件直接对燃油消耗的影响”，那是不够的，因为你必须先知道发动机如何影响汽车速度，再知道速度如何影响燃油消耗。  \n",
    "- 同理，计算 \\(\\frac{\\partial L}{\\partial \\theta}\\) 必须先计算 \\(\\frac{\\partial L}{\\partial z(t_1)}\\)，然后结合 \\(\\frac{\\partial z(t_1)}{\\partial \\theta}\\)。\n",
    "\n",
    "### 4. 数值求解器中的情况\n",
    "\n",
    "假设我们用欧拉法求解 ODE：\n",
    "$\\[\n",
    "z(t_1) = z(t_0) + h \\cdot f(z(t_0), t_0, \\theta)\n",
    "\\]$\n",
    "在这种情况下，$\\(z(t_1)\\)$ 明显依赖于 $\\(\\theta\\)$（因为 $\\(f\\)$ 依赖于 $\\(\\theta\\)$）。在反向传播时，我们首先需要计算损失 $\\(L\\)$ 对 $\\(z(t_1)\\)$ 的梯度 $\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$（这可以看作“当前输出误差”），再根据欧拉法的计算关系，传播这个梯度回去，计算出参数 $\\(\\theta\\)$ 对输出的影响。\n",
    "\n",
    "如果没有计算 $\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$，我们就不知道如何根据输出变化去调整参数——就好比不知道“速度变化对燃油消耗的影响”，那就无法调整发动机部件来改善燃油经济性。\n",
    "\n",
    "### 5. 总结\n",
    "\n",
    "- **为什么不直接计算 $\\(\\frac{\\partial L}{\\partial \\theta}\\)$？**  \n",
    "  因为 $\\(z(t_1)\\)$ 是通过求解 ODE 得到的，它是参数 $\\(\\theta\\)$ 的一个复杂函数。为了应用链式法则，我们必须先计算出损失对中间变量（ODE 解 $\\(z(t_1)\\)$）的敏感性，也就是 $\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$，再利用这个信息传播回参数 $\\(\\theta\\)$。\n",
    "  \n",
    "- **反向传播中**：  \n",
    "  你先计算 $\\(\\frac{\\partial L}{\\partial z(t_1)}\\)$，接着再利用 ODE 求解器（例如通过伴随敏感性方法）计算 $\\(\\frac{\\partial z(t_1)}{\\partial \\theta}\\)$，二者相乘就得到了最终的 $\\(\\frac{\\partial L}{\\partial \\theta}\\)$。\n",
    "\n",
    "希望这个解释能够帮助你理解为什么在 Neural ODE 中，我们不仅需要计算损失关于参数的梯度，还必须计算损失关于 ODE 解 $\\(z(t_1)\\)$ 的梯度。如果还有任何疑问，请继续提问！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "208055bf7b9854c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 为什么在反向传播时，通常需要反向传播每一时刻的中间状态，来计算梯度？\n",
    "这段话的意思是，在传统的神经网络反向传播中，我们通常是逐层计算梯度的，每一层的输出都会被存储，方便后续计算梯度时使用。而在 **Neural ODE** 中，反向传播的过程与传统神经网络不同，因为它是通过求解一个微分方程（ODE）来获得最终的网络状态 $\\( z(t_1) \\)$。\n",
    "\n",
    "让我们详细理解一下：\n",
    "\n",
    "### 1. **传统神经网络反向传播**\n",
    "在传统的神经网络（比如前馈神经网络）中，前向传播过程是逐层进行的，每一层的输入和输出都会在计算过程中被存储，以便在反向传播时计算梯度。具体来说，反向传播过程是通过链式法则逐层计算梯度的：\n",
    "\n",
    "- 在前向传播时，每一层的输入 $\\( x_k \\)$ 和输出 $\\( y_k \\)$ 都被计算出来。\n",
    "- 在反向传播时，我们从最后一层开始，依次计算每一层的梯度。这需要访问每一层的输入和输出。\n",
    "\n",
    "这种方式的优点是每一层都有明确的输入输出，容易计算并且能够直接存储每一层的中间状态。然而，随着网络的深度增加，存储每一层的中间结果会消耗大量的内存，尤其是在很深的网络或者非常大的数据集上。\n",
    "\n",
    "### 2. **Neural ODE 的反向传播**\n",
    "在 **Neural ODE** 中，前向传播是通过求解一个常微分方程（ODE）来得到网络的最终状态 $\\( z(t_1) \\)$，而不是通过逐层传递输入和输出。具体来说，Neural ODE 将网络看作一个连续的动态系统，状态 $\\( z(t) \\)$ 随时间 $\\( t \\)$ 演化：\n",
    "\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "\\]$\n",
    "\n",
    "这个方程定义了网络在时间 $\\( t \\)$ 上的变化。\n",
    "\n",
    "#### 反向传播时的问题：\n",
    "为了计算网络参数 $\\(\\theta\\)$ 的梯度，我们需要通过链式法则计算损失 $\\( L \\)$ 对参数 $\\(\\theta\\)$ 的导数。为了正确地计算这个梯度，我们需要知道每个时刻的状态 \\( z(t) \\)，即我们需要存储每个时间步的中间状态。因为每个时间步的状态都与上一个时间步的状态有关系，因此在传统的逐步计算中，我们必须将每个时刻的状态值都存储下来，才能在反向传播时计算梯度。\n",
    "\n",
    "例如：\n",
    "- **前向传播时**：我们通过数值求解器（比如欧拉法或 Runge-Kutta 法）从初始时刻 $\\( t_0 \\)$ 计算到终止时刻 $\\( t_1 \\)$，得到状态 $\\( z(t_1) \\)$。这个计算可能需要记录多个时间步的中间状态。\n",
    "- **反向传播时**：为了计算梯度，我们需要依赖这些中间状态来计算每个时间步的梯度。如果每个时间步都需要用到前一个时间步的状态，那么就必须存储每个时间步的状态。\n",
    "\n",
    "如果我们使用 **简单的欧拉法**（Euler method）来求解 ODE，假设我们将时间区间 $\\([t_0, t_1]\\)$ 分成很多小步，每个步长为 $\\(h\\)$，那么在前向传播过程中我们可能需要存储每个时间步的 $\\(z(t)\\)$。在反向传播过程中，我们会利用这些存储的中间状态来计算每个时刻的梯度。\n",
    "\n",
    "### 3. **内存消耗的原因**\n",
    "由于在前向传播中我们需要保存每个时间步的中间状态 $\\(z(t)\\)$，如果时间步数很多（即时间跨度很长或步长很小），那么 **存储所有中间状态** 的内存消耗会非常大。这会导致内存开销的急剧增加，尤其是在长时间序列或高维数据的情况下。\n",
    "\n",
    "\n",
    "\n",
    "### 4. **伴随敏感性方法的优势**\n",
    "为了避免存储大量的中间状态，Neural ODE 引入了 **伴随敏感性方法（Adjoint Sensitivity Method）**，它通过反向求解伴随方程来避免存储所有中间状态。\n",
    "\n",
    "- **反向传播的关键**：我们不再需要存储每个时间步的 $\\(z(t)\\)$，而是通过伴随方程（adjoint equation）计算梯度。具体来说，伴随方程描述了梯度如何随时间反向传播，而我们只需要存储最终的状态和伴随状态，而不需要每个时间步的状态。\n",
    "  \n",
    "- **内存优化**：通过伴随敏感性方法，反向传播时我们只需要存储**最后的状态 \\( z(t_1) \\)** 和 **伴随状态 \\( a(t_1) \\)**，然后从终点 \\( t_1 \\) 开始反向传播。通过这种方法，内存消耗大大减少。\n",
    "\n",
    "### 5. **总结**\n",
    "- 在 **传统神经网络的反向传播** 中，每一层的输入和输出需要被存储，以便计算梯度。\n",
    "- 在 **Neural ODE 中**，前向传播依赖于微分方程的数值解，而反向传播则依赖于每个时刻的中间状态。这意味着，如果我们要进行传统的反向传播，必须存储每个时间步的状态，这会导致内存消耗巨大。\n",
    "- **伴随敏感性方法** 通过引入伴随状态，允许我们仅存储最终状态和伴随状态，从而避免了存储每个时间步的状态，极大减少了内存消耗。\n",
    "\n",
    "希望这个解释能够清楚地帮助你理解为什么在 Neural ODE 中，传统反向传播需要存储中间状态，以及伴随敏感性方法如何帮助减少内存消耗。如果还有其他问题，欢迎继续提问！"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104f5a9e9f65963c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 为什么要计算每个$t$下的$\\theta$？网络中的$\\theta$不是只有一个吗?\n",
    "\n",
    "你的疑问很关键，实际上，$\\(\\theta\\)$ 确实只有一个，但反向传播过程中，我们需要计算损失对不同时间步的 **状态** $\\( z(t) \\)$ 的梯度，而不仅仅是对 $\\(\\theta\\)$ 的梯度。让我们一步步拆解这个问题。\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Neural ODE 中的 $\\(\\theta\\)$**\n",
    "在 Neural ODE 中，网络参数 $\\(\\theta\\)$ 不是随时间变化的，而是一个**固定的参数集**，用于定义 ODE 的右侧函数：\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "\\]$\n",
    "这个 $\\( f \\)$ 通常是一个神经网络，其参数 $\\(\\theta\\)$ 是我们要训练的内容。\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 反向传播时为什么要计算不同时间步 $\\( t \\)$ 的状态梯度？**\n",
    "虽然 $\\(\\theta\\)$ 是固定的，但 **状态 $\\( z(t) \\)$ 在不同时间步都是不同的**，而损失 $\\( L \\)$ 直接依赖于最终状态 $\\( z(t_1) \\)$，所以计算梯度时，我们需要知道损失 $\\( L \\)$ 对整个状态轨迹 $\\( z(t) \\)$ 的影响。\n",
    "\n",
    "在反向传播时，我们要求的目标是：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta}\n",
    "\\]$\n",
    "但由于 $\\( \\theta \\)$ 并不是直接影响损失 $\\( L \\)$ 的变量，而是通过 **ODE 影响 $\\( z(t) \\)$ 进而影响 $\\( L \\)$**，因此我们需要用链式法则展开梯度计算：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} \\frac{dL}{dz(t)} \\cdot \\frac{dz(t)}{d\\theta} dt\n",
    "\\]$\n",
    "这个积分意味着我们需要计算损失 $\\( L \\)$ 对 **每个时间步 $\\( z(t) \\)$ 的梯度** $\\( \\frac{dL}{dz(t)} \\)$，然后再计算 $\\( \\frac{dz(t)}{d\\theta} \\)$ 以最终求出 $\\( \\frac{dL}{d\\theta} \\)$。\n",
    "\n",
    "因此，我们不是在计算“每个 $\\( t \\)$ 的 $\\(\\theta\\)$”，而是在计算“损失 $\\( L \\)$ 对不同时间点 $\\( z(t) \\)$ 的梯度”，以便最终获得 $\\(\\theta\\)$ 的梯度。\n",
    "\n",
    "这个问题很好！让我们仔细分析一下。\n",
    "\n",
    "### **反向传播的计算步骤**\n",
    "\n",
    "在 **Neural ODE** 中，反向传播的目标是计算损失 \\( L \\) 对参数 \\( \\theta \\) 的梯度：  \n",
    "\\[\n",
    "\\frac{dL}{d\\theta}\n",
    "\\]\n",
    "但是，计算这个梯度的过程中，涉及到了状态 \\( z(t) \\) 的连续演化。我们需要利用链式法则来一步步展开，最终得到关于 \\( \\theta \\) 的梯度。\n",
    "\n",
    "所以，计算 **梯度的过程** 是通过 **每一步都计算 \\( \\frac{dL}{dz(t)} \\) 和 \\( \\frac{dz(t)}{d\\theta} \\)** 来进行的，并不是先计算所有的 \\( \\frac{dL}{dz(t)} \\)，然后再算 \\( \\frac{dz(t)}{d\\theta} \\)。\n",
    "\n",
    "**具体来说，反向传播的过程是这样进行的：**\n",
    "\n",
    "### **1. 正向传播过程：**\n",
    "在正向传播中，给定初始状态 $\\( z(t_0) \\)$，我们通过解微分方程得到 $\\( z(t) \\)$ 在每个时间步的状态，直到最终状态 $\\( z(t_1) \\)$。这个过程通常是通过数值积分器（比如 Runge-Kutta 或 Euler 方法）来计算的。\n",
    "\n",
    "### **2. 反向传播过程：**\n",
    "反向传播的核心是在每个时间步 $\\( t \\)$ 上计算梯度，过程是从 $\\( t_1 \\)$ 反向传播到 $\\( t_0 \\)$。\n",
    "\n",
    "#### **计算 $\\( \\frac{dL}{dz(t)} \\)$：**\n",
    "1. **首先，** 我们从最终的状态 $\\( z(t_1) \\)$ 开始，计算损失 $\\( L \\)$ 对 $\\( z(t_1) \\)$ 的梯度 $\\( \\frac{dL}{dz(t_1)} \\)$。\n",
    "2. 然后，根据链式法则，这个梯度会沿着时间反向传播。在反向传播时，我们要计算 **每个时间步的梯度** $\\( \\frac{dL}{dz(t)} \\)$。\n",
    "3. 在每个时间步 $\\( t \\)$，这个梯度 $\\( \\frac{dL}{dz(t)} \\)$ 依赖于前一步的梯度。具体来说，**每一步的 $\\( \\frac{dL}{dz(t)} \\)$ 都需要用前一步的 $\\( \\frac{dL}{dz(t+1)} \\)$** 来计算（即从 $\\( t_1 \\)$ 反向传递到 $\\( t_0 \\)$）。\n",
    "\n",
    "#### **计算 $\\( \\frac{dz(t)}{d\\theta} \\)$：**\n",
    "4. 然后，我们需要计算每个时间步 $\\( t \\)$ 上的梯度 $\\( \\frac{dz(t)}{d\\theta} \\)$，这部分与 **ODE 的解有关**，也就是神经网络参数 $\\( \\theta \\)$ 如何影响每个时间步的状态变化。\n",
    "5. 在反向传播时，**每个时间步**的 $\\( \\frac{dz(t)}{d\\theta} \\)$ 都会被计算出来，并与 $\\( \\frac{dL}{dz(t)} \\)$ 结合，利用链式法则逐步计算出最终的 $\\( \\frac{dL}{d\\theta} \\)$。\n",
    "\n",
    "### **所以，反向传播的流程是：**\n",
    "- 在每个时间步 $\\( t \\)$，我们都需要同时计算 **损失 $\\( L \\)$ 对状态 $\\( z(t) \\)$ 的梯度 $\\( \\frac{dL}{dz(t)} \\)$** 和 **状态 $\\( z(t) \\)$ 对参数 $\\( \\theta \\)$ 的梯度 $\\( \\frac{dz(t)}{d\\theta} \\)$**。\n",
    "- 然后将这两个梯度结合，通过链式法则逐步反向传播，最终计算出损失函数 $\\( L \\)$ 对网络参数 $\\( \\theta \\)$ 的梯度。\n",
    "\n",
    "### **总结：**\n",
    "- **不是先计算所有 $\\( \\frac{dL}{dz(t)} \\)$，再计算 $\\( \\frac{dz(t)}{d\\theta} \\)$**，而是 **每一步都同时计算这两个梯度**，然后结合链式法则进行反向传播。\n",
    "- 每个时间步的 **$\\( \\frac{dL}{dz(t)} \\)$** 和 **$\\( \\frac{dz(t)}{d\\theta} \\)$** 是逐步计算并逐步传递的。\n",
    "\n",
    "这样反向传播是从 $\\( t_1 \\)$ 到 $\\( t_0 \\)$，一步一步进行的，而不是等所有的 $\\( \\frac{dL}{dz(t)} \\)$ 计算完之后再计算 $\\( \\frac{dz(t)}{d\\theta} \\)$。\n",
    "\n",
    "希望这个解释能帮助你更清楚地理解反向传播的过程！如果还有疑问，随时告诉我！\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 为什么这会导致大量内存消耗？**\n",
    "在传统的神经网络（比如 ResNet）中，反向传播计算梯度时，只需要存储前向传播的中间激活值（比如每一层的输出），然后逐层计算梯度。而在 **Neural ODE** 中，我们的“层”是一个连续时间区间 $\\([t_0, t_1]\\)$，数值积分器会把这个时间区间划分成许多小步 $\\( t_0, t_1, \\dots, t_n \\)$，每个小步都会有一个状态 $\\( z(t_i) \\)$。  \n",
    "\n",
    "如果直接存储所有这些状态 $\\( z(t) \\)$ 以备反向传播使用，就会消耗大量内存。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41fdb01fa3ea1548"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 怎么理解积分求梯度？\n",
    "\n",
    "在反向传播过程中，**每个时间步的梯度计算**是分两步进行的，而你提到的“结合过程”确实与 **积分** 相关，但是这不是直接的积分计算，而是通过数值求解的方式来逼近积分结果。\n",
    "\n",
    "### **梯度计算中的“结合”过程与积分的关系**\n",
    "\n",
    "#### 1. **梯度计算的目标：**\n",
    "\n",
    "我们希望计算 **损失函数** $\\( L \\)$ 对 **网络参数** $\\( \\theta \\)$ 的梯度：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta}\n",
    "\\]$\n",
    "这个过程涉及到状态 $\\( z(t) \\)$ 和网络参数 $\\( \\theta \\)$ 之间的关系。因为 $\\( z(t) \\)$ 是通过解微分方程得到的，而这个解与 $\\( \\theta \\)$ 有直接关系，所以在计算梯度时，我们需要通过 **链式法则** 来分解计算：\n",
    "\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} \\frac{dL}{dz(t)} \\cdot \\frac{dz(t)}{d\\theta} dt\n",
    "\\]$\n",
    "\n",
    "这个公式中的 **积分** 反映了我们要对每个时间步 $\\( t \\)$ 进行累计。**每个时间步的“结合”过程** 就是沿着时间方向进行梯度计算并进行累积，这样最终我们可以得到损失对参数 $\\( \\theta \\)$ 的梯度。\n",
    "\n",
    "#### 2. **每个时间步的“结合”过程**\n",
    "\n",
    "反向传播时，具体步骤是：\n",
    "\n",
    "- **每个时间步 $\\( t \\)$，** 我们都需要同时计算：\n",
    "  - **损失对状态的梯度** $\\( \\frac{dL}{dz(t)} \\)$。\n",
    "  - **状态对参数的梯度** $\\( \\frac{dz(t)}{d\\theta} \\)$。\n",
    "  \n",
    "  然后这两个梯度被结合起来，通过 **链式法则** 计算出每个时间步的 **梯度贡献**。\n",
    "\n",
    "- 这些梯度贡献会被 **累计**，以求出损失对参数 $\\( \\theta \\)$ 的总梯度。在数学上，这个“累计”过程就是 **对每个时间点的梯度进行积分**。\n",
    "\n",
    "#### 3. **与积分的关系：**\n",
    "\n",
    "回到积分的公式：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} \\frac{dL}{dz(t)} \\cdot \\frac{dz(t)}{d\\theta} dt\n",
    "\\]$\n",
    "\n",
    "这里的 **积分** 反映了对时间区间 $\\([t_0, t_1]\\)$ 内每个时间步的梯度进行累计的过程。**每个时间步的梯度** 就是我们在反向传播时要计算的梯度 $\\(\\frac{dL}{dz(t)}\\)$ 和 $\\(\\frac{dz(t)}{d\\theta}\\)$ 的乘积。**通过数值方法**（比如 Euler 法、Runge-Kutta 方法等），我们可以在每个时间步计算梯度，并将这些梯度 **累加起来**，近似得到总的梯度。\n",
    "\n",
    "#### 4. **数值求解与实际操作**\n",
    "\n",
    "在实际操作中，我们不会直接去求解这个积分，而是通过数值积分方法来近似计算。比如：\n",
    "\n",
    "- 在正向传播时，我们用数值积分器解微分方程，得到 $\\( z(t) \\)$ 在每个时间步的状态。\n",
    "- 在反向传播时，我们通过数值求解 **沿着时间反向计算每个时间步的梯度**，然后将它们累加，这个过程就是通过数值方式 **逼近积分**。\n",
    "\n",
    "通过这种方式，我们能在有限的计算资源下，近似得到这个积分的值，从而计算出损失函数对参数 $\\( \\theta \\)$ 的梯度。\n",
    "\n",
    "---\n",
    "\n",
    "### **总结：**\n",
    "\n",
    "- 反向传播中的 **“结合”过程** 其实是指每个时间步的梯度计算，它们会通过链式法则 **累积**，从而得到最终的总梯度。\n",
    "- 这个“累积”过程确实与 **积分** 是紧密相关的，最终的梯度计算就是通过 **对每个时间步的梯度进行积分** 来完成的。\n",
    "- 在实际操作中，这个积分是通过 **数值方法** 来逼近的（例如 Runge-Kutta 或 Euler 法）。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3863b6194fdb5324"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 伴随敏感性方法（Adjoint Sensitivity Method）\n",
    "**伴随敏感性方法**（Adjoint Sensitivity Method）在 **Neural ODE** 中的应用正是为了 **减少内存消耗**，通过 **不存储每个时间步的状态**，而是通过反向求解一个伴随微分方程来计算梯度。\n",
    "\n",
    "### 伴随敏感性方法的核心概念：\n",
    "\n",
    "伴随敏感性方法的基本思想是利用 **微分方程的可逆性**，反向传播时通过求解与原始微分方程（ODE）相关的伴随方程来计算梯度，而不需要在内存中存储所有时间步的中间状态 $\\( z(t) \\)$。\n",
    "\n",
    "### 伴随敏感性方法在 Neural ODE 中的具体步骤：\n",
    "\n",
    "1. **正向传播：**\n",
    "   - 首先我们解原始的 ODE，计算 $\\( z(t) \\)$ 的轨迹。这个轨迹是通过数值方法（如 Euler 法、Runge-Kutta 方法等）解得的：\n",
    "     $\\[\n",
    "     \\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "     \\]$\n",
    "   - 得到从 $\\( t_0 \\)$ 到 $\\( t_1 \\)$ 的状态轨迹 $\\( z(t) \\)$，这是正向传播过程。\n",
    "\n",
    "2. **引入伴随变量：**\n",
    "   - 伴随方法的关键是引入伴随变量 $\\( a(t) \\)$，它表示损失函数 $\\( L \\)$ 对状态 $\\( z(t) \\)$ 的梯度：\n",
    "     $\\[\n",
    "     a(t) = \\frac{dL}{dz(t)}\n",
    "     \\]$\n",
    "   - 这些伴随变量会在反向传播过程中沿时间反向传播。\n",
    "\n",
    "3. **反向传播（解伴随 ODE）：**\n",
    "   - 在反向传播时，我们**不直接存储 $\\( z(t) \\)$**，而是通过求解 **伴随 ODE** 来计算梯度。伴随 ODE 的形式是：\n",
    "     $\\[\n",
    "     \\frac{da(t)}{dt} = -a(t) \\cdot \\frac{\\partial f(z(t), t, \\theta)}{\\partial z}\n",
    "     \\]$\n",
    "   - 这个方程描述了伴随变量的动态行为，它是原始 ODE 的反向过程。我们沿着时间逆向传播，计算梯度信息。\n",
    "\n",
    "4. **计算最终梯度：**\n",
    "   - 最终，网络的参数 $\\( \\theta \\)$ 的梯度通过积分公式计算：\n",
    "     $\\[\n",
    "     \\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} \\frac{da(t)}{dt} \\cdot \\frac{dz(t)}{d\\theta} dt\n",
    "     \\]$\n",
    "   - 这个梯度就是我们用来更新参数 $\\( \\theta \\)$ 的信息。\n",
    "\n",
    "### 内存优化：\n",
    "\n",
    "- 传统的反向传播方法通常需要在每个时间步存储 $\\( z(t) \\)$ 以便计算梯度。这在长时间序列或深度神经网络中会导致巨大的内存开销。\n",
    "  \n",
    "- **伴随敏感性方法** 通过不存储所有时间步的状态 $\\( z(t) \\)$，而是在反向传播时通过求解伴随 ODE 来计算梯度。这样，内存消耗仅依赖于当前时间步的计算结果，而不需要保存整个时间序列的状态，显著减少了内存开销。\n",
    "\n",
    "### 总结：\n",
    "\n",
    "- **伴随敏感性方法** 是一种用于计算 **微分方程** 中参数梯度的技术，它通过引入 **伴随变量** 并解伴随 ODE 来优化梯度计算，避免存储所有时间步的状态，进而减少内存消耗。\n",
    "- 在 **Neural ODE** 中，这种方法帮助我们以较低的内存成本计算参数梯度，同时保留了通过微分方程求解的连续时间建模优势。\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# **伴随敏感性方法（Adjoint Sensitivity Method）详细推导**  \n",
    "我们现在从头推导 **伴随敏感性方法**，并解释它在 **Neural ODE** 中的应用。\n",
    "\n",
    "\n",
    "## **1. Neural ODE 的基本方程**  \n",
    "\n",
    "在 **Neural ODE** 中，我们用一个参数化的函数 $\\( f(z, t, \\theta) \\)$ 代替离散层的计算，使得隐藏状态 $\\( z(t) \\)$ 满足以下微分方程：\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z, t, \\theta), \\quad z(t_0) = z_0\n",
    "\\]$\n",
    "我们使用 **数值求解** 这个 ODE 来得到最终的状态 $\\( z(t_1) \\)$，然后计算损失：\n",
    "$\\[\n",
    "L = \\ell(z(t_1))\n",
    "\\]$\n",
    "目标是计算损失 $\\( L \\)$ 对参数 $\\( \\theta \\)$ 的梯度，即：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta}\n",
    "\\]$\n",
    "---\n",
    "\n",
    "## **2. 直接反向传播的高内存问题**\n",
    "通常的反向传播方法需要存储整个 $\\( z(t) \\)$ 轨迹，然后使用 **反向求解 ODE** 计算梯度：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} \\frac{\\partial L}{\\partial z} \\frac{\\partial z}{\\partial \\theta} dt\n",
    "\\]$\n",
    "但是存储整个 $\\( z(t) \\)$ 轨迹会导致 **高内存消耗**，尤其是在 ODE 时间步很多时。\n",
    "\n",
    "**为了解决这个问题，伴随敏感性方法（Adjoint Method）不存储 \\( z(t) \\) 轨迹，而是引入** **伴随变量** \\( a(t) \\) **，通过解 ODE 计算梯度**。\n",
    "\n",
    "---\n",
    "\n",
    "## **3. 伴随变量的定义**\n",
    "定义 **伴随变量** \\( a(t) \\)（也称为伴随状态）：\n",
    "$\\[\n",
    "a(t) = \\frac{dL}{dz(t)}\n",
    "\\]$\n",
    "这表示损失函数 $\\( L \\)$ 对状态 $\\( z(t) \\)$ 的梯度。**我们希望沿着时间反向求解 $\\( a(t) \\)$**。\n",
    "\n",
    "---\n",
    "\n",
    "## **4. 伴随方程的推导**\n",
    "我们要计算 $\\( a(t) \\)$ 在时间上的变化，即 **$\\( da(t) / dt \\)$ 的形式**。\n",
    "\n",
    "根据链式法则：\n",
    "$\\[\n",
    "\\frac{da(t)}{dt} = \\frac{d}{dt} \\left( \\frac{dL}{dz(t)} \\right)\n",
    "\\]$\n",
    "\n",
    "根据 Neural ODE：\n",
    "$\\[\n",
    "\\frac{dz(t)}{dt} = f(z, t, \\theta)\n",
    "\\]$\n",
    "\n",
    "两边对 $\\( z(t) \\)$ 求导：\n",
    "$\\[\n",
    "\\frac{d}{dt} \\left( \\frac{dL}{dz} \\right) = \\frac{dL}{dz} \\cdot \\frac{d}{dt} \\left( \\frac{dz}{dz} \\right)\n",
    "\\]$\n",
    "\n",
    "但由于 $\\( z(t) \\)$ 是由 ODE 计算的，我们可以利用 **ODE 的偏导数**：\n",
    "$\\[\n",
    "\\frac{dz}{dt} = f(z, t, \\theta) \\Rightarrow \\frac{d}{dz} \\left( \\frac{dz}{dt} \\right) = \\frac{\\partial f}{\\partial z}\n",
    "\\]$\n",
    "\n",
    "代入：\n",
    "$\\[\n",
    "\\frac{da(t)}{dt} = - a(t) \\cdot \\frac{\\partial f(z, t, \\theta)}{\\partial z}\n",
    "\\]$\n",
    "\n",
    "这就是 **伴随 ODE** 的形式！  \n",
    "它表示如何通过反向求解 ODE 来计算梯度。\n",
    "\n",
    "---\n",
    "\n",
    "## **5. 计算参数梯度**\n",
    "有了 $\\( a(t) \\)$，我们就可以计算参数 $\\( \\theta \\)$ 的梯度：\n",
    "$\\[\n",
    "\\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} a(t) \\cdot \\frac{\\partial f}{\\partial \\theta} dt\n",
    "\\]$\n",
    "这表示：\n",
    "- 我们在反向求解 $\\( a(t) \\)$ 的过程中，可以 **累积梯度信息**，而不需要存储整个 $\\( z(t) \\)$ 轨迹。\n",
    "\n",
    "---\n",
    "\n",
    "## **6. 伴随方法的计算流程**\n",
    "我们现在总结 **伴随方法的梯度计算步骤**：\n",
    "\n",
    "1. **正向传播**：\n",
    "   - 解 ODE 计算 $\\( z(t) \\)$ 轨迹，得到最终状态 $\\( z(t_1) \\)$。\n",
    "\n",
    "2. **反向传播（解伴随 ODE）**：\n",
    "   - 令 $\\( a(t_1) = \\frac{dL}{dz(t_1)} \\)$，即损失对最终状态的梯度。\n",
    "   - 反向求解 ODE **计算 $\\( a(t) \\)$**，满足：\n",
    "     $\\[\n",
    "     \\frac{da(t)}{dt} = - a(t) \\cdot \\frac{\\partial f}{\\partial z}\n",
    "     \\]$\n",
    "   - 这一步 **不会存储整个 $\\( z(t) \\)$ 轨迹**，而是直接计算梯度。\n",
    "\n",
    "3. **计算参数梯度**：\n",
    "   - 在反向求解过程中计算：\n",
    "     $\\[\n",
    "     \\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} a(t) \\cdot \\frac{\\partial f}{\\partial \\theta} dt\n",
    "     \\]$\n",
    "   - 通过积分累积参数梯度。\n",
    "\n",
    "---\n",
    "\n",
    "## **7. 伴随方法的优势**\n",
    " **降低内存消耗**：  \n",
    "- **不存储整个 $\\( z(t) \\)$ 轨迹**，而是通过 **反向求解 ODE** 计算梯度。\n",
    "\n",
    " **适用于长时间序列**：  \n",
    "- 传统方法存储所有时间步的 $\\( z(t) \\)$ 状态，导致长时间序列 ODE 无法计算，而伴随方法解决了这个问题。\n",
    "\n",
    " **适用于深度学习中的 ODE**：  \n",
    "- 在 **Neural ODE** 训练过程中，可以用伴随方法优化梯度计算，提高效率。\n",
    "\n",
    "---\n",
    "\n",
    "## **8. 总结**\n",
    "- **直接反向传播需要存储整个 $\\( z(t) \\)$ 轨迹，内存消耗高**。\n",
    "- **伴随敏感性方法** **不存储轨迹**，而是通过 **伴随 ODE** 计算梯度：\n",
    "  $\\[\n",
    "  \\frac{da(t)}{dt} = - a(t) \\cdot \\frac{\\partial f}{\\partial z}\n",
    "  \\]$\n",
    "- **梯度计算通过积分累积**：\n",
    "  $\\[\n",
    "  \\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} a(t) \\cdot \\frac{\\partial f}{\\partial \\theta} dt\n",
    "  \\]$\n",
    "- **优点**：大幅降低内存消耗，适用于长时间序列 ODE。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0a532a3ee7616e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **1. 伴随变量（Adjoint Variable）是什么？**\n",
    "在 **Neural ODE** 的梯度计算中，我们引入一个新的变量 **\\( a(t) \\)**，它表示损失函数 **\\( L \\)** 对 **状态 \\( z(t) \\)** 的梯度：\n",
    "\\[\n",
    "a(t) = \\frac{dL}{dz(t)}\n",
    "\\]\n",
    "这个变量 **\\( a(t) \\)** 被称为 **伴随变量（Adjoint Variable）**，它衡量了在每个时间点 \\( t \\) 上，状态 \\( z(t) \\) 的变化对最终损失 \\( L \\) 的影响。\n",
    "\n",
    "换句话说，伴随变量 \\( a(t) \\) 是我们在反向传播过程中真正关心的东西，它告诉我们如何调整 \\( z(t) \\) 以最小化损失。\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 伴随方程（Adjoint Equation）是什么？**\n",
    "我们已经知道在前向传播时，\\( z(t) \\) 由以下 ODE 计算得到：\n",
    "\\[\n",
    "\\frac{dz}{dt} = f(z, t, \\theta)\n",
    "\\]\n",
    "但在 **反向传播时，我们需要计算梯度**，即损失 \\( L \\) 对状态 \\( z(t) \\) 和参数 \\( \\theta \\) 的影响。\n",
    "\n",
    "我们希望求解 **伴随变量 \\( a(t) \\) 的变化规律**，这就是**伴随方程（Adjoint Equation）**：\n",
    "\\[\n",
    "\\frac{da(t)}{dt} = -a(t) \\cdot \\frac{\\partial f(z, t, \\theta)}{\\partial z}\n",
    "\\]\n",
    "它表示：\n",
    "- 伴随变量 \\( a(t) \\) 在时间 \\( t \\) 上的变化，可以用 \\( z(t) \\) 对 \\( f(z, t, \\theta) \\) 的偏导数计算。\n",
    "- 这个方程是一个 **ODE**，我们可以沿着时间**反向求解**它，从而得到梯度信息。\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 伴随方法是如何工作的？**\n",
    "整个 **伴随敏感性方法（Adjoint Sensitivity Method）** 的核心思想就是 **利用伴随方程计算梯度，而不存储整个 \\( z(t) \\) 轨迹**，以节省内存。\n",
    "\n",
    "#### **步骤如下**：\n",
    "1. **正向传播（Forward Pass）**：\n",
    "   - 从初始状态 \\( z_0 \\) 通过数值求解 ODE，计算最终状态 \\( z(t_1) \\)。\n",
    "   - 计算损失 \\( L = \\ell(z(t_1)) \\)。\n",
    "\n",
    "2. **初始化伴随变量**：\n",
    "   - 在最终时刻 \\( t_1 \\)，我们计算：\n",
    "     \\[\n",
    "     a(t_1) = \\frac{dL}{dz(t_1)}\n",
    "     \\]\n",
    "   - 这表示损失对最终状态的梯度。\n",
    "\n",
    "3. **反向求解伴随方程**：\n",
    "   - 通过 **解伴随 ODE**：\n",
    "     \\[\n",
    "     \\frac{da(t)}{dt} = -a(t) \\cdot \\frac{\\partial f}{\\partial z}\n",
    "     \\]\n",
    "   - 从 \\( t_1 \\) 逆向求解到 \\( t_0 \\)，得到 **\\( a(t) \\) 的轨迹**。\n",
    "\n",
    "4. **计算参数梯度**：\n",
    "   - 在反向传播过程中，我们可以通过积分计算参数梯度：\n",
    "     \\[\n",
    "     \\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} a(t) \\cdot \\frac{\\partial f}{\\partial \\theta} dt\n",
    "     \\]\n",
    "\n",
    "---\n",
    "\n",
    "### **4. 为什么伴随方法比直接反向传播更省内存？**\n",
    "✅ **不存储 \\( z(t) \\) 轨迹**：  \n",
    "- 传统反向传播要存储整个 ODE 轨迹（每个时间步的 \\( z(t) \\)），导致高内存消耗。\n",
    "- 伴随方法**只存储当前时间步的 \\( a(t) \\)**，在反向传播时重新计算梯度。\n",
    "\n",
    "✅ **避免计算所有时间步的中间梯度**：  \n",
    "- 传统方法需要对每个时间步都存储 \\( \\frac{dL}{dz(t)} \\) 并计算梯度。\n",
    "- 伴随方法通过 **求解 ODE** 直接获得梯度信息。\n",
    "\n",
    "---\n",
    "\n",
    "### **5. 直观理解：伴随变量 \\( a(t) \\) 就像“倒推影响”**\n",
    "- 设想一个系统在 \\( t_0 \\) 开始，沿时间演化到 \\( t_1 \\) 产生结果 \\( z(t_1) \\)。\n",
    "- 伴随变量 \\( a(t) \\) **倒推这个过程**，告诉我们每个时间步的状态对损失的贡献，并引导梯度计算。\n",
    "- **计算梯度时，我们不是存储整个过程，而是重新求解一个逆向 ODE 来获得信息**。\n",
    "\n",
    "---\n",
    "\n",
    "### **6. 伴随方法的本质**\n",
    "- **前向传播：** 计算 $\\( z(t) \\)$ 轨迹，但不存储所有时间步的状态。\n",
    "- **反向传播：** 通过解 **伴随方程** 计算梯度，而不是存储整个 $\\( z(t) \\)$ 轨迹。\n",
    "- **优点：** 极大地降低内存消耗，使得 **Neural ODE 可以训练更深、更复杂的模型**。\n",
    "\n",
    "---\n",
    "\n",
    "### **7. 总结**\n",
    "| **概念**                | **数学定义**                                                             | **作用**                                     |\n",
    "|-----------------------|----------------------------------------------------------------------|--------------------------------------------|\n",
    "| **伴随变量 $\\( a(t) \\)$** | $\\( a(t) = \\frac{dL}{dz(t)} \\)$                                      | 反向传播时计算损失对状态的梯度                            |\n",
    "| **伴随方程**              | $\\( \\frac{da(t)}{dt} = -a(t) \\cdot \\frac{\\partial f}{\\partial z} \\)$ | 计算 $\\( a(t) \\)$ 的演化，避免存储整个 $\\( z(t) \\)$ 轨迹 |\n",
    "| **伴随方法**              | 用 ODE 反向求解梯度                                                         | 降低内存消耗，提高训练效率                              |\n",
    "\n",
    "如果你对某部分还不太清楚，可以告诉我，我可以再换个角度解释 😊"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "396d52e06b8bbfde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 对比一下 **引入伴随变量前后** 计算损失的方式\n",
    "\n",
    "### **1. 不引入伴随变量（传统方法）**\n",
    "在传统的神经网络和 **Neural ODE** 中，如果没有引入伴随变量 $\\( a(t) \\)$，在 **反向传播时**，需要通过 **每个时间步的中间状态 $\\( z(t) \\)$** 计算损失对参数 $\\( \\theta \\)$ 的梯度。这种方式会涉及存储 **每个时间步的状态 $\\( z(t) \\)$**，并计算这些状态对损失函数的影响。\n",
    "\n",
    "**前向传播：**\n",
    "- 通过数值解法（如欧拉法、Runge-Kutta法等）解微分方程：\n",
    "  $\\[\n",
    "  \\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "  \\]$\n",
    "  从初始状态 $\\( z(t_0) \\)$ 到最终状态 $\\( z(t_1) \\)$。\n",
    "\n",
    "**损失计算：**\n",
    "- 假设我们得到 $\\( z(t_1) \\)$ 并计算损失 $\\( L = \\ell(z(t_1)) \\)$，其中 $\\( \\ell \\)$ 是损失函数。\n",
    "\n",
    "**反向传播：**\n",
    "- 需要对每个时间步的状态 $\\( z(t) \\)$ 进行反向传播：\n",
    "  $\\[\n",
    "  \\frac{dL}{dz(t)} = \\text{梯度（由损失函数决定）}\n",
    "  \\]$\n",
    "- 逐步反向传播每个时间步的梯度，直到达到初始状态 $\\( z(t_0) \\)$。\n",
    "- 由于每个时间步都需要存储 $\\( z(t) \\)$，因此 **内存开销非常大**。\n",
    "\n",
    "**梯度计算：**\n",
    "- 在传统方法中，计算每个时间步的梯度时，需要使用 **链式法则**：\n",
    "  $\\[\n",
    "  \\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} \\frac{dL}{dz(t)} \\cdot \\frac{dz(t)}{d\\theta} dt\n",
    "  \\]$\n",
    "  由于需要存储每个 $\\( z(t) \\)$，导致 **内存消耗巨大**。\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 引入伴随变量（伴随敏感性方法）**\n",
    "\n",
    "引入 **伴随变量 $\\( a(t) \\)$** 后，我们不再需要存储每个时间步的 $\\( z(t) \\)$，而是通过求解一个伴随方程来反向传播损失，节省了内存。\n",
    "\n",
    "**前向传播：**\n",
    "- 同样通过数值解法解微分方程：\n",
    "  $\\[\n",
    "  \\frac{dz(t)}{dt} = f(z(t), t, \\theta)\n",
    "  \\]$\n",
    "  从初始状态 $\\( z(t_0) \\)$ 到最终状态 $\\( z(t_1) \\)$ 计算。\n",
    "\n",
    "**损失计算：**\n",
    "- 计算损失 $\\( L = \\ell(z(t_1)) \\)$。\n",
    "\n",
    "**反向传播：**\n",
    "- **初始化伴随变量**：\n",
    "  计算损失 $\\( L \\)$ 对 $\\( z(t_1) \\)$ 的梯度（在终点处）：\n",
    "  $\\[\n",
    "  a(t_1) = \\frac{dL}{dz(t_1)}\n",
    "  \\]$\n",
    "  \n",
    "- **解伴随方程**：\n",
    "    为了计算参数 $\\( \\theta \\)$ 对损失的影响，我们需要计算 **伴随变量 $\\( a(t) \\)$** 如何随着时间变化。这个计算通过求解伴随方程来完成：\n",
    "    $\\[\n",
    "    \\frac{da(t)}{dt} = -a(t) \\cdot \\frac{\\partial f(z(t), t, \\theta)}{\\partial z(t)}\n",
    "    \\]$\n",
    "    这里，$\\( \\frac{\\partial f(z(t), t, \\theta)}{\\partial z(t)} \\)$ 是微分方程的函数 $\\( f(z(t), t, \\theta) \\)$ 对状态 $\\( z(t) \\)$ 的偏导数，表示系统如何对状态变化敏感。\n",
    "    \n",
    "    - **注意**：伴随方程是沿着时间逆向求解的，反映了损失对 $\\( z(t) \\)$ 的变化如何影响 $\\( a(t) \\)$。\n",
    "\n",
    "- **计算梯度**：\n",
    "    接下来，我们就可以通过伴随变量来计算梯度：\n",
    "    $\\[\n",
    "    \\frac{dL}{d\\theta} = \\int_{t_0}^{t_1} a(t) \\cdot \\frac{\\partial f}{\\partial \\theta} dt\n",
    "    \\]$\n",
    "    这里，$\\( a(t) \\)$ 是我们通过解伴随方程得到的，表示损失相对于状态 $\\( z(t) \\)$ 的变化率。通过这个公式，我们不再需要存储 $\\( z(t) \\)$，而只需要存储伴随变量 $\\( a(t) \\)$，从而大大节省了内存。\n",
    "    \n",
    "    优点：\n",
    "    \n",
    "    - 在反向传播过程中，我们 **不再存储每个时间步的 $\\( z(t) \\)$**，而是通过解伴随方程计算梯度。\n",
    "    - 因此，节省了大量的内存，尤其是在时间步数很多的情况下。\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 对比总结：**\n",
    "\n",
    "| **步骤**           | **传统方法（不引入伴随变量）**                                    | **引入伴随变量（伴随敏感性方法）**                |\n",
    "|--------------------|------------------------------------------------------|------------------------------------|\n",
    "| **前向传播**       | 解微分方程计算 $\\( z(t) \\)$ 轨迹，从 $\\( t_0 \\)$ 到 $\\( t_1 \\)$。 | 同样解微分方程，得到 $\\( z(t) \\)$ 轨迹。        |\n",
    "| **损失计算**       | 计算损失 $\\( L = \\ell(z(t_1)) \\)$                        | 计算损失 $\\( L = \\ell(z(t_1)) \\)$。     |\n",
    "| **反向传播**       | 存储所有的 $\\( z(t) \\)$ 轨迹，并计算每个时间步的梯度。                   | 通过伴随方程计算梯度，而不需要存储 $\\( z(t) \\)$ 轨迹。 |\n",
    "| **梯度计算**       | 计算损失对 $\\( z(t) \\)$ 的梯度，并通过链式法则逐步反向传播。                | 使用伴随变量 $\\( a(t) \\)$ 和伴随方程来计算梯度。    |\n",
    "| **内存消耗**       | 需要存储所有 $\\( z(t) \\)$ 轨迹，内存消耗较大。                       | 只需要存储 $\\( a(t) \\)$，节省内存。           |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. 关键区别：**\n",
    "- **传统方法**：在反向传播时，需要存储每个时间步的 $\\( z(t) \\)$，并逐步计算梯度，这样导致巨大的内存消耗。\n",
    "- **伴随方法**：在反向传播时，我们只需要存储 **伴随变量 \\( a(t) \\)**，并通过解伴随方程计算梯度。这样，大大减少了内存的开销，特别是在需要解较长时间序列的 ODE 时，优势更加明显。\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f86833452109b246"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "490978ae1276b069"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c2fae91742e71e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c8afca0511bc0a48"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "328f08df82ef3a60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
